{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3ff5bd-d1fa-4498-b1b2-ba6124d50981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a2386d-c38c-41c5-a1b8-e7cbb3d6f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "file=open(\"frankenstein.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d180bc-81cc-4c3e-9ac8-2c782f720b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "#standardization\n",
    "def tokenize_words(input):\n",
    "    input=input.lower()\n",
    "    tokenizer=RegexpTokenizer(r'\\w+')\n",
    "    tokens=tokenizer.tokenize(input)\n",
    "    filtered=filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \"\".join(filtered)\n",
    "    \n",
    "processed_inputs=tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9ba3c9-6ad9-43d6-b6ce-e3c164266ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chars to numbers\n",
    "chars= sorted(list(set(processed_inputs)))\n",
    "char_to_num= dict((c,i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d4386e-6502-49f9-b5d3-5b8db9c5ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 232972\n",
      "Total vocab: 37\n"
     ]
    }
   ],
   "source": [
    "#check if words to char or chars to num has worked\n",
    "input_len=len(processed_inputs)\n",
    "vocab_len=len(chars)\n",
    "print(\"Total number of characters:\", input_len)\n",
    "print(\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5baa523-caa2-471f-a56a-d20c2bd27c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq length\n",
    "seq_length=100\n",
    "x_data=[]\n",
    "y_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2f67e7-9fd7-4904-b74d-7b434547682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns: 232872\n"
     ]
    }
   ],
   "source": [
    "#loop through the sequence\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq=processed_inputs[i:i+seq_length]\n",
    "    out_seq=processed_inputs[i+seq_length]\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "\n",
    "n_patterns=len(x_data)\n",
    "print(\"Total patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542556c1-0b2a-4a6d-b751-b826c179f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert input sequence to np array and so on\n",
    "X= numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X=X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b10a267-1a48-4d4b-97a7-3de90aa2df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encoding\n",
    "y=to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d01c9f5-66a7-4a29-968e-fa9ca372b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eshaan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#creating the model\n",
    "model= Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0,2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0,2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0,2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88acc04-f7d5-41f0-92d1-a1e482ab79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2afc51e8-f1c1-4ab2-a7e2-9430ec149af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving weights\n",
    "filepath=\"model_weights_saved.keras\"\n",
    "checkpoint=ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b41f55a9-b909-433d-84f9-e1e5c02a69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.9382\n",
      "Epoch 1: loss improved from None to 2.91548, saving model to model_weights_saved.keras\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1737s\u001b[0m 2s/step - loss: 2.9155\n",
      "Epoch 2/4\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.9089\n",
      "Epoch 2: loss improved from 2.91548 to 2.90923, saving model to model_weights_saved.keras\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1731s\u001b[0m 2s/step - loss: 2.9092\n",
      "Epoch 3/4\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.9095\n",
      "Epoch 3: loss improved from 2.90923 to 2.90898, saving model to model_weights_saved.keras\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1761s\u001b[0m 2s/step - loss: 2.9090\n",
      "Epoch 4/4\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 2.8908\n",
      "Epoch 4: loss improved from 2.90898 to 2.87789, saving model to model_weights_saved.keras\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1752s\u001b[0m 2s/step - loss: 2.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23ff47a6000>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model and training\n",
    "model.fit(X,y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b1f10a-32d4-4fd5-9f0d-8df50ef91bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eshaan\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 24 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "#recompileing model with same weights\n",
    "filename=\"model_weights_saved.keras\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01680396-dcd3-4baa-8d3c-a2b501e95731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output of the model back into characters\n",
    "num_to_char=dict((i,c) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6575d99f-cf85-4235-a95b-4c65e98be015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: \n",
      "\" g s m i n d s e i z e d l i k e l i c h e n r o c k w i s h e d s o m e t i m e s s h a k e t h o u g h t f e e l i n g l e a r n e d o n e m e a n s o v e r c o m e s e n s a t i o n p a i n d e a t \"\n"
     ]
    }
   ],
   "source": [
    "#random seeds to help generate\n",
    "start=numpy.random.randint(0, len(x_data)-1)\n",
    "pattern=x_data[start]\n",
    "print(\"Random Seed: \")\n",
    "print(\"\\\"\", ' '.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49c6a48c-6dc2-4081-bce2-424cec26cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
     ]
    }
   ],
   "source": [
    "#generate the text\n",
    "for i in range(1000):\n",
    "    x=numpy.reshape(pattern, (1,len(pattern),1))\n",
    "    x=x/float(vocab_len)\n",
    "    prediction=model.predict(x, verbose=0)\n",
    "    index=numpy.argmax(prediction)\n",
    "    result=num_to_char[index]\n",
    "    seq_in=[num_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern=pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef109b62-a730-45d1-bd19-891b06643faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
